---
title: "Introduction to CDAP"
output:
  html_document:
    toc: yes
    toc_float: true
    toc_depth: 5
date: "30/06/2022"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Logging in  

To access CDAP, go to this link to the [PROD environment](https://adb-7480336463633201.1.azuredatabricks.net/?o=7480336463633201#) which all users have access to. If you have access to other environments, you can access those from the same link. If it is not working, make sure you have followed the steps to active your account on the Azure Active Directory, as explained in your Welcome email.  


## Environments  

Most users will have access to the PROD environment only, but for some purposes access to other environments can be granted. The infographic shows the differences between the environments and how they relate to data held in CDAP. For more information on the different environments, see the DASH playbook.


## Clusters 

An Azure Databricks cluster is a set of computation resources and configurations on which you run your work. Different clusters are optimised for different tasks, for example some are optimised for smaller tasks, whereas others are optimised for bigger tasks. They have different packages and libraries installed on them.  Details of the different clusters on CDAP can be found in the DASH playbook.  

Read more about clusters on the [Databricks documentation](https://docs.microsoft.com/en-gb/azure/databricks/).  

The clusters that are available on CDAP are detailed in the DASH playbook.

## Data

The CDAP data lake contains data that have been uploaded for users. You can access the data for your analysis, upload your own data (up to 2GB in size) and also request that data are added to the data lake. See more details in the Dash Playbook.

## The Databricks workspace  

When you first log into CDAP, you will see a similar screen to the below, showing what is available with Databricks. Some of these features are advanced, and primarily aimed at people using Databricks notebooks for Machine Learning, so you might not need them. If you will be working in RStudio, you will not need most of these tabs, except the Cluster tab which takes you to RStudio on CDAP. See the list below the image for an explanation of the different parts and what they are for.  
  

```{r, echo = FALSE, out.width = '75%'}
knitr::include_graphics("images/image2.png", dpi = NA)
```

  
  
1. Landing pages. Changing between landing pages will change the links that appear on the main page, as well as some of the menu options. The options are:  
    - Data Science and Engineering  
    - Machine Learning  
    - SQL  
2. Create. For creating:  
    - Databricks notebooks  
    - Tables (for uploading into Databricks File Store (DBFS))  
    - Clusters (not possible for most Defra group users)  
    - Jobs (task list)  
    - Repo (add repo from GitHub)  
    - AutoML Experiment  
3. Workspace. Change between shared workspaces, your own workspace, and other users' workspaces that you have been given access to.  
4. Repos. Connect Databricks Notebooks to GitHub.  
5. Recent. Access your recent notebooks.  
6. Search workspace.  
7. Data. Click on DBFS to find data from the data lake that is accessible to all, or that you have been granted permission to use.  
8. Compute. Access the different clusters.  
9. Workflows. See your task list.  
10. Partner Connect. Not currently available.  
11. Help. Access to:  
    - Help centre  
    - Release notes  
    - Documentation  
    - Knowledge base  
    - Databricks status  
    - Feedback  
12. Settings. To access user settings such as git integration, notebook setup, default language.  
13. Environments. Most people will be in the PROD environment, but if you do have access to other environments, you can change them here.  
14. Menu options.  

## Creating Databricks notebooks 

A notebook is a web-based interface to a document that contains runnable code, visualisations, and narrative text. A Databricks notebook is similar to RMarkdown or a jupyter notebook.  

Find out about how to create notebooks and how to work with them from the [Databricks documentation](https://docs.microsoft.com/en-gb/azure/databricks/notebooks/). We have also added training materials for working in Databricks notebooks. Go back to the main site to access them.

## Working with RStudio 

It is possible to run R in Databricks notebooks, but you can also use an online version of RStudio through CDAP. We have added training materials on working with RStudio in CDAP. Go back to the main site to access them.