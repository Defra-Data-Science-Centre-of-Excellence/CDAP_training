---
title: "Introduction to the DASH Platform"
output:
  html_document:
    toc: yes
    toc_float: true
    toc_depth: 5
date: "27/07/2022"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, out.width = '50%'}
knitr::include_graphics("images/DASH.png", dpi = NA)
```

## What is the DASH Platform?

The Data Analytics and Science Hub, previously named the common data analytics platform (CDAP), has been created to provide analysts and scientists within Defra group access to a wider range of datasets, advanced tooling and compute power. It is currently in the Public Beta testing phase, with plans to iteratively increase user numbers to 1000 users by April 2024. 

## Logging in  

To access the DASH Platform, go to this link to the [PROD environment](https://adb-7393756451346106.6.azuredatabricks.net/) which all users have access to. If you have access to other environments, you can access those from the same link. 

You should see the following image and click on `Sign in with Azure AD` to get to your workspace:


```{r, echo = FALSE, out.width = '75%'}
knitr::include_graphics("images/image1.png", dpi = NA)
```


If it is not working, make sure you have followed the steps to active your account on the Azure Active Directory, as explained in your Welcome email.  


## Environments  

Most users will have access to the PROD environment only, but for some purposes access to other environments can be granted. For more information on the different environments, see the DASH Platform playbook.


## Clusters 

An Azure Databricks cluster is a set of computation resources and configurations on which you run your work. Different clusters are optimised for different tasks, for example some are optimised for smaller tasks, whereas others are optimised for bigger tasks. They have different packages and libraries installed on them.  

Read more about clusters in general on the [Databricks documentation](https://docs.microsoft.com/en-gb/azure/databricks/).  

The clusters that are available on the platform are detailed in the DASH Platform Playbook.  

Clusters need to be turned on in order for work to happen on them. If you will be using RStudio, this will not affect you as the cluster that RStudio uses will be left on. If you use Databricks however, you will need to ask for a cluster you want to use to be turned on. You should request this by asking the person in your team who has the rights to turn clusters on, also called the business admin.   

## Data

Data on the platform are held within 3 different zones in an area called the data lake. The raw zone contains raw data that cannot be accessed by users, the base zone contains data that have been converted and users can access, and the lab zone contains data added by the users in their individual directories. The lab zone can contain data that has been added from the base zone that has been converted by you for your own use, as well as additional data that you can upload yourself (up to 2GB). 

You can access the details of the DASH Platform data catalogue on [SharePoint](https://defra.sharepoint.com/:x:/r/teams/Team552/Data%20Information/Data%20Strategy%20and%20Engagement/Current%20Projects/CDAP%20-%20(Original%20Environmental%20Analytics%20and%20Reporting)/CDAP%20Data%20Catalogue/CDAP%20Data%20Catalogue.xlsx?d=w7c345456e15c4f47b474985d0aae7f14&csf=1&web=1). To view available datasets, select **Available in CDAP (Data loaded in Public Beta/MVP2)'='Y'**.

More details can be found in the DASH Platform playbook.  


## The Databricks workspace  

When you first log into the DASH Platform, you will see a similar screen to the below, showing what is available with Databricks. Some of these features are advanced, and primarily aimed at people using Databricks notebooks for Machine Learning, so you might not need them. If you will be working in RStudio, you will not need most of these tabs, except the Cluster tab which takes you to RStudio on the platform. See the list below the image for an explanation of the different parts and what they are for.  
  

```{r, echo = FALSE, out.width = '75%'}
knitr::include_graphics("images/image2.png", dpi = NA)
```

  
  
1. Landing pages. Changing between landing pages will change the links that appear on the main page, as well as some of the menu options. The options are:  
    - Data Science and Engineering  
    - Machine Learning  
    - SQL  
2. Create. For creating:  
    - Databricks notebook  
    - Table (for uploading into Databricks File Store (DBFS))  
    - Cluster (not currently possible)  
    - Job (task list)  
    - Pipeline  
    - Repo (add repo from GitHub)  
    - AutoML Experiment  
3. Workspace. Change between shared workspaces, your own workspace, and other users' workspaces that you have been given access to.  
4. Repos. Connect Databricks Notebooks to GitHub.    
5. Recent. Access your recent notebooks.  
6. Search workspace.  
7. Data. Click on DBFS to find data from the data lake that is accessible to all, or that you have been granted permission to use.  
8. Compute. Access the different clusters.  
9. Workflows. See your task list.  
10. Partner Connect. Not currently available.  
11. Help. Access to:  
    - Help centre  
    - Release notes  
    - Documentation  
    - Knowledge base  
    - Databricks status  
    - Privacy policy  
    - Feedback  
12. Settings. To access user settings such as git integration, notebook settings, language settings.  
13. Environments. Most people will be in the PROD environment, but if you do have access to other environments, you can switch here.  

## What are Databricks notebooks?  

A notebook is a web-based interface to a document that contains runnable code, visualisations, and narrative text. A Databricks notebook is similar to RMarkdown or a jupyter notebook.  

Find out about how to create notebooks and how to work with them from the [Databricks documentation](https://docs.microsoft.com/en-gb/azure/databricks/notebooks/). We have also added training materials for working in Databricks notebooks. Go back to the main site to access them.

## Working with RStudio 

It is possible to run R in Databricks notebooks, but you can also use an online version of RStudio through CDAP. We have added training materials on working with RStudio on the platform. Go back to the main site to access them.